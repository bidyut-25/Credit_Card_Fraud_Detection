{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNFddM1wKeQB",
        "outputId": "03dcf50e-12ec-41a3-c8bd-51c8b34fdd5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from flask-ngrok) (2.32.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (2025.8.3)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn imbalanced-learn flask joblib flask-ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTeJxyRLLXXQ",
        "outputId": "0df45a21-9e5c-43dc-db8d-4758f56fb21f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original training data size: 164845 samples\n",
            "Original test data size: 41212 samples\n",
            "Original training class distribution:\n",
            "Class\n",
            "0.0    164519\n",
            "1.0       326\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "\n",
        "# --- NEW STEP ---\n",
        "# Drop any rows with missing values to ensure clean data for evaluation\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Original training data size: {len(X_train)} samples\")\n",
        "print(f\"Original test data size: {len(X_test)} samples\")\n",
        "print(f\"Original training class distribution:\\n{y_train.value_counts()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3QJFAwDMDVf",
        "outputId": "8ddae562-8b66-432e-ef2d-db35d1f55369"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resampled training data size: 329038 samples\n",
            "Resampled training class distribution:\n",
            "Class\n",
            "0.0    164519\n",
            "1.0    164519\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['scaler.pkl']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Scale the 'Time' and 'Amount' features\n",
        "scaler = StandardScaler()\n",
        "X_train[['Time', 'Amount']] = scaler.fit_transform(X_train[['Time', 'Amount']])\n",
        "X_test[['Time', 'Amount']] = scaler.transform(X_test[['Time', 'Amount']])\n",
        "\n",
        "# Apply SMOTE to the training data only\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"Resampled training data size: {len(X_resampled)} samples\")\n",
        "print(f\"Resampled training class distribution:\\n{y_resampled.value_counts()}\")\n",
        "\n",
        "# Train the Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Save the trained model and the scaler for deployment\n",
        "joblib.dump(model, 'fraud_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRUbOLiWNRw9",
        "outputId": "f72deccf-b38a-421c-eef2-61f73ce2ed43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Confusion Matrix ---\n",
            "[[41142     3]\n",
            " [   10    57]]\n",
            "\n",
            "--- Classification Report ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00     41145\n",
            "         1.0       0.95      0.85      0.90        67\n",
            "\n",
            "    accuracy                           1.00     41212\n",
            "   macro avg       0.97      0.93      0.95     41212\n",
            "weighted avg       1.00      1.00      1.00     41212\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"--- Confusion Matrix ---\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\n--- Classification Report ---\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83ulzJqwNoxp",
        "outputId": "9f4fcef7-d261-4817-f1b7-0cb5d4061a5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
        "                           param_grid=param_grid,\n",
        "                           cv=5,\n",
        "                           scoring='f1',\n",
        "                           verbose=2,\n",
        "                           n_jobs=-1)\n",
        "\n",
        "# Fit the grid search to the resampled training data\n",
        "grid_search.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Print the best parameters and the best score\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best F1-score: {grid_search.best_score_}\")\n",
        "\n",
        "# Use the best model for predictions\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_tuned = best_model.predict(X_test)\n",
        "\n",
        "# Print the final classification report\n",
        "print(classification_report(y_test, y_pred_tuned))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vpdefqc-QfCR"
      },
      "outputs": [],
      "source": [
        "# Save the best model and the scaler\n",
        "joblib.dump(grid_search.best_estimator_, 'fraud_model_tuned.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
